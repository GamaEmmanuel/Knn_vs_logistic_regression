{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Credit Card Fraud Detection (10 pts)\n",
    "\n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (1 pts)\n",
    "Load the data from `fraud_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of fraud observation  1.6410823768035772\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"fraud_data.csv\")\n",
    "\n",
    "## Print the percentage of fraud observations\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)  # Your code here\n",
    "print(\"Percentage of fraud observation \", (list(y).count(1)/len(y))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What percentage of the observations in the dataset are instances of fraud? 1.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the majority class label (4pts)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? (Here accuracy is the ratio of the number of correctly classified transactions to the total number of transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuray: 0.9852507374631269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "## Instantiate and fit a dummy classifier that always predict class label by the majority class of the training data\n",
    "## Use DummyClassifier in sklearn with strategy 'most_frequent\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "dummy_test_pred = dummy.predict(X_test)\n",
    "\n",
    "## Measure test accuracy of your dummy classifier\n",
    "dummy_test_acc = accuracy_score(y_test, dummy_test_pred)\n",
    "\n",
    "\n",
    "print('Dummy classifier accuray:', dummy_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the accuracy of the dummy classifier look (very low, low, high, very high)? \n",
    "\n",
    "It is very high. This is due the fact that we have unbalanced data (frauds are less than 2%), therefore when we predict that every instance will be non fraudulent (98.5 %). So we are only mistaking in the 1.64%  that is fraudulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How many fraudulent transactions are correctly classified? Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Measure test recall score of your dummy classifier\n",
    "dummy_test_recall = recall_score(y_test, dummy_test_pred)\n",
    "\n",
    "print('Dummy classifier recall:', dummy_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the recall of the dummy classifier look (very low, low, high, very high)? \n",
    "It is very low, because we are not classifing any of the flaudulent transactions correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a logistic regression model (3pts)\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9964970501474927\n",
      "Logistic classifier recall: 0.7875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "## Instantiate a logistic regression model and fit to the training data\n",
    "logR = LogisticRegression()\n",
    "logR.fit(X_train, y_train)\n",
    "logR_test_pred = logR.predict(X_test)\n",
    "\n",
    "\n",
    "## Measure test accuracy \n",
    "logR_test_acc = accuracy_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results of logistic regression with those of the above dummy classifier*\n",
    "\n",
    "The results of the logistic regresion are much better than the ones from the dummy clasifier in both metrics but specially in the recall measure because now we are able to identify fraudulent transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for selecting hyperparameters for Logistic Regression (2pts)\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9963126843657817\n",
      "Logistic classifier recall: 0.775\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Define the grid of logistic regression parameters\n",
    "parameters = {\"penalty\":[\"l1\",\"l2\"],\"C\": [0.01, 0.1, 1, 10, 100]}\n",
    "model = LogisticRegression()\n",
    "    \n",
    "## Perform grid search CV to find best model parameter setting\n",
    "cmodel = GridSearchCV(model, param_grid=parameters, cv=3)\n",
    "cmodel.fit(X_train, y_train)\n",
    "\n",
    "best_C =cmodel.best_estimator_.C\n",
    "best_penalty = cmodel.best_estimator_.penalty\n",
    "\n",
    "## Fit logistic regression with best parameters to the entire training data\n",
    "model = LogisticRegression(C=best_C, penalty=best_penalty)\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "logR_test_pred = model.predict(X_test)\n",
    "\n",
    "## Measure test accuracy\n",
    "logR_test_acc = accuracy_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test, logR_test_pred)\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results with that of logistic regression with default parameters*\n",
    "\n",
    "Accuracy is slightly worst when we do grid search. I belive this happens because the range of parameter is not sufficiently large to include the optimal solution. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
